{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for data import from dataset.py(in sec):6.961822509765625e-05\n",
      "Time taken for data/modules import(in sec):0.0010085105895996094\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "\n",
    "#Import training data and labels from the other python file\n",
    "from dataset import data, label\n",
    "\n",
    "# Count elapsed time and print it\n",
    "elapsed = time.time() - t\n",
    "print(\"Time taken for data import from dataset.py(in sec):\"+str(elapsed))\n",
    "\n",
    "#importing modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras import optimizers, metrics\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Count elapsed time for import and print it\n",
    "elapsed = time.time() - t\n",
    "print(\"Time taken for data/modules import(in sec):\"+str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data shape\n",
    "\n",
    "data_shape=data.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters= 32, kernel_size = 5, input_shape=(data_shape,1)))\n",
    "model.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='sigmoid'))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "#model.add(Activation(\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/blackwater/anaconda3/envs/ml/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Configures the model for training\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Splitting: Train, test\n",
    "\n",
    "X_Train, X_test, y_Train, y_test = train_test_split(data, label, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train to train, CV\n",
    "\n",
    "X_train, X_CV, y_train, y_CV = train_test_split(X_Train, y_Train, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/blackwater/anaconda3/envs/ml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/blackwater/anaconda3/envs/ml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/1\n",
      "4860/4860 [==============================] - 16s 3ms/step - loss: 0.2547 - acc: 0.5023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3df47fe610>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training : Trains the model for a given number of epochs (iterations on a dataset)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/540 [==============================] - 1s 1ms/step\n",
      "Evaluation score is  [0.25128359844287235, 0.5018518571224477]\n"
     ]
    }
   ],
   "source": [
    "#evaluate: Returns the loss value & metrics values(accuracy) for the model in test mode.\n",
    "\n",
    "score = model.evaluate(X_CV, y_CV, batch_size=10)\n",
    "print(\"Evaluation score is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output predictions\n",
      "600/600 [==============================] - 1s 1ms/step\n",
      "Evaluation score is  [0.2530241916577021, 0.48000000876684984]\n"
     ]
    }
   ],
   "source": [
    "#Generates output predictions for the input samples\n",
    "\n",
    "predictions = model.predict(X_test, batch_size=None, verbose=0)\n",
    "print(\"Output predictions\")\n",
    "score = model.evaluate(X_test, y_test, batch_size=10)\n",
    "print(\"Evaluation score is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions, y_test\n",
    "\n",
    "v = np.empty([600, 2]) \n",
    "v[:,0] = predictions[:,0]\n",
    "v[:,1]= y_test[:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the value to a text file\n",
    "\n",
    "np.savetxt(\"a.txt\",v,fmt='%4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4633981  0.        ]\n",
      " [0.46296778 1.        ]\n",
      " [0.46235052 0.        ]\n",
      " ...\n",
      " [0.46182591 0.        ]\n",
      " [0.46143883 1.        ]\n",
      " [0.4601393  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Print the predictions vs y_test value\n",
    "\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
